{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import platform"
      ],
      "metadata": {
        "id": "XcqiC6qIpPkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"CONFIGURATION VARIABLES\"\"\"\n",
        "rows_to_be_dropped = [\"Conversion\", \"Conversion \" ,\"Marketing Input\", \"TV - Home\", \"GRPs estimated for News Dark Period\" ]\n",
        "columns_to_be_dropped = [\"comments\"]\n",
        "\n",
        "fiction_1 = pd.read_excel(\"/content/Colors Data - For Analysis 6th June update (1).xlsx\", sheet_name=0,  skiprows=2, dtype=\"str\")\n",
        "# Clean column names\n",
        "fiction_1.columns = fiction_1.columns.str.lower().str.replace(\"-\", \"\").str.replace(\" \", \"_\")\n",
        "fiction_1 = fiction_1.loc[:, ~fiction_1.columns.str.startswith(\"unnamed\")]\n",
        "fiction_1 = fiction_1.drop(columns = columns_to_be_dropped)\n",
        "\n",
        "# Rename column 'shows' to 'metric'\n",
        "fiction_1.rename(columns={\"shows\": \"metric\"}, inplace=True)\n",
        "fiction_1['metric'] = fiction_1['metric'].str.strip()\n",
        "\n",
        "fiction_1.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# drop irrelevant\n",
        "fiction_1 = fiction_1[~fiction_1['metric'].isin(rows_to_be_dropped)].dropna(how=\"all\")"
      ],
      "metadata": {
        "id": "R-B_NFfLXiO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fiction_1.reset_index(drop= True, inplace = True)\n",
        "# fiction_1"
      ],
      "metadata": {
        "id": "p6En_c5Cwuil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_columns =   list(fiction_1[\"metric\"])\n",
        "# new_columns.insert(0, \"shows\")\n",
        "\n",
        "# # making the new dataframe to chnge the rows\n",
        "# main_data = pd.DataFrame(columns = new_columns)\n",
        "\n",
        "# for i in range(len(new_columns)) :\n",
        "#   if i == 0 :\n",
        "#     data = list(fiction_1.columns)[1:]\n",
        "#     main_data[new_columns[i]] = data\n",
        "#   else :\n",
        "#     data = fiction_1.iloc[i-1, 1:].values\n",
        "#     main_data[new_columns[i]] = list(data)\n",
        "\n",
        "# main_data.columns = main_data.columns.str.lower().str.replace(\"-\", \"\").str.replace(\" \", \"_\")"
      ],
      "metadata": {
        "id": "2tlZ-d_H_q-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markers = [\"Launch Performance\", \"Conversion Launch Day\", \"Conversion Launch Week\", \"Star Plus Slot Reach% (Pre 4 Wks)\",  \"Campaign GRPs (Home)\", \"TV - NW Spends\", \"TV - OSN Spends\", \"Digital\",  \"Social Video Spends (YT, FB, Insta, Sharechat, etc)\", \"OTT Spends (Hotstar, Zee5, etc.)\", \"GDN/Programmatic/Xasis Spends\", \"Sub-mediums\", \"Other Spends (Glance, Zapr, CTV, etc.)\", \"Overall Digital  Spends\", \"Spends on Influencers & Paid Reviews - CAT A\", \"Other Marketing Spends\", \"Owned & Earned Social Media\", \"Earned Media - PR\", \"Cross Network GRPs Broken By Genre till Launch Week\", \"OSN GRPs Broken By Genre till Launch Week\", \"Previous slot Daily Avg Reach % in Launch week\"]\n",
        "data_groups = []\n",
        "\n",
        "for ind in range(len(markers)):\n",
        "    if ind==0:\n",
        "        start_index = 0\n",
        "        end_entry = markers[ind]\n",
        "        end_index = fiction_1.index[fiction_1['metric'] == end_entry][0]-1\n",
        "        data = fiction_1.loc[start_index:end_index]\n",
        "        data_groups.append(data)\n",
        "        start_entry = markers[ind]\n",
        "        end_entry = markers[ind+1]\n",
        "        start_index = fiction_1.index[fiction_1['metric'] == start_entry][0]\n",
        "        end_index = fiction_1.index[fiction_1['metric'] == end_entry][0]-1\n",
        "        data = fiction_1.loc[start_index:end_index]\n",
        "        data_groups.append(data)\n",
        "    elif ((ind>0) & (ind<=len(markers)-2)):\n",
        "        start_entry = markers[ind]\n",
        "        end_entry = markers[ind+1]\n",
        "        start_index = fiction_1.index[fiction_1['metric'] == start_entry][0]\n",
        "        end_index = fiction_1.index[fiction_1['metric'] == end_entry][0]-1\n",
        "        data = fiction_1.loc[start_index:end_index]\n",
        "        data_groups.append(data)\n",
        "    else:\n",
        "        start_entry = markers[ind]\n",
        "        start_index = fiction_1.index[fiction_1['metric'] == start_entry][0]\n",
        "        end_index = len(fiction_1)+1\n",
        "        data = fiction_1.loc[start_index:end_index]\n",
        "        data_groups.append(data)\n",
        "\n",
        "data_long = []\n",
        "\n",
        "for i in range(len(data_groups)):\n",
        "    df = pd.DataFrame(data_groups[i])\n",
        "    df = df.loc[:, df.columns.notna()]\n",
        "    df2  = df.T.reset_index(drop=True)\n",
        "    df2.columns = df2.iloc[0]\n",
        "    df2 = df2.drop(0)\n",
        "    df2[\"shows\"] = list(df.columns)[1:]\n",
        "    df2 = df2.dropna(axis = 1, how=   \"all\")\n",
        "    df2.reset_index(drop=True, inplace=True)\n",
        "    columns = [\"shows\"] + [col for col in df2.columns if col != \"shows\"]\n",
        "    main_df = df2[columns]\n",
        "    main_df.columns = main_df.columns.str.lower().str.replace(\"-\", \"\").str.replace(\" \", \"_\")\n",
        "    data_long.append(main_df)\n",
        "\n",
        "\n",
        "show_details, launch_perf, conversion_ld, conversion_lw, comp_chan_rch, tv_home_promo, tv_nw_promo, tv_osn_promo, digi_tg, social_media, ott, gdn_prog, sub_mediums, others_glance_zapr, overall_digi_spends, influencers, dth_ooh_oga_cin_celeb, social_own_earn, pr_earned_new_metrics, nw_grp_split, osn_grp_split, pre_slot_rch = data_long[0], data_long[1], data_long[2], data_long[3], data_long[4], data_long[5], data_long[6], data_long[7], data_long[8], data_long[9], data_long[10], data_long[11], data_long[12], data_long[13], data_long[14], data_long[15], data_long[16], data_long[17], data_long[18], data_long[19], data_long[20], data_long[21]"
      ],
      "metadata": {
        "id": "ViywyKFf4mHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_date(date_str):\n",
        "  try:\n",
        "    if \"'\" in date_str:\n",
        "      parts = date_str.split('-')\n",
        "      day = parts[0]\n",
        "      month = parts[1][:3]\n",
        "      year = '20' + parts[1][4:]\n",
        "      new_date_str = f\"{day}-{month}-{year}\"\n",
        "      return pd.to_datetime(new_date_str, format='%d-%b-%Y')\n",
        "    else:\n",
        "      return pd.to_datetime(date_str)\n",
        "  except Exception as e:\n",
        "      return pd.NaT"
      ],
      "metadata": {
        "id": "QzRQeMuD0vAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## show details\n",
        "\n",
        "show_details['launch_date'] = show_details['launch_date'].apply(convert_date)\n",
        "show_details['year'] = show_details['launch_date'].dt.year\n",
        "show_details['month'] = show_details['launch_date'].dt.month\n",
        "show_details['day'] = show_details['launch_date'].dt.day\n",
        "\n",
        "\n",
        "show_details = show_details.rename(columns={'mf/ss': 'mf_ss'})\n",
        "show_details['slot_time'] = show_details['slot_time'].astype('category')\n",
        "show_details['mf_ss'] = show_details['mf_ss'].astype('category')\n",
        "show_details['genre'] = show_details['genre'].astype('category')\n",
        "show_details['prominent_leads_(if_any)'] = show_details['prominent_leads_(if_any)'].apply(lambda x: 'yes' if pd.notnull(x) else 'no').astype(\"category\")\n",
        "show_details['celebrity_endorsers_(if_any)'] = show_details['celebrity_endorsers_(if_any)'].apply(lambda x: 'yes' if pd.notnull(x) else 'no').astype(\"category\")\n",
        "show_details['regional_remake_(pls_specify)'] = show_details['regional_remake_(pls_specify)'].apply(lambda x: 'yes' if pd.notnull(x) else 'no').astype(\"category\")"
      ],
      "metadata": {
        "id": "dkQvYkxj_ANG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Launch Performance\n",
        "\n",
        "def time_to_seconds(time_str):\n",
        "  if pd.notna(time_str):\n",
        "    time_parts = time_str.split(':')\n",
        "    hours = int(time_parts[0])\n",
        "    minutes = int(time_parts[1])\n",
        "    seconds = float(time_parts[2])\n",
        "    return hours * 3600 + minutes * 60 + seconds\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "def format_time(seconds):\n",
        "  if pd.notna(seconds) :\n",
        "    mins = seconds // 60\n",
        "    secs = seconds % 60\n",
        "    return f\"{int(mins)}.{int(secs)}\"\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "launch_perf_time_col = [\"pre_4_wks_tsv\", \"ld_tsv\"\t, \"lw_tsv\"]\n",
        "for col in launch_perf_time_col :\n",
        "    launch_perf[col] = launch_perf[col].apply(time_to_seconds)\n",
        "    launch_perf[col] = launch_perf[col].apply(format_time)\n",
        "\n",
        "launch_perf = launch_perf.replace(\"-\", \"0\")\n",
        "launch_perf = launch_perf.apply(pd.to_numeric, errors = \"ignore\")"
      ],
      "metadata": {
        "id": "oYdeTS8F7Lcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## conversion Launch Day\n",
        "conversion_ld_col =  [col+\"(till_ld)\" for col in conversion_ld.columns if col != \"shows\"]\n",
        "conversion_ld.columns = [\"shows\"] + conversion_ld_col\n",
        "\n",
        "for col in conversion_ld_col :\n",
        "    conversion_ld[col] = conversion_ld[col].apply(pd.to_numeric, errors = 'coerce')"
      ],
      "metadata": {
        "id": "ERzYZ6Iz7Lan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## conversion Launch Week\n",
        "conversion_lw_col =  [col+\"(till_lw)\" for col in conversion_lw.columns if col != \"shows\"]\n",
        "conversion_lw.columns = [\"shows\"] + conversion_lw_col\n",
        "\n",
        "for col in conversion_lw_col :\n",
        "    conversion_lw[col] = conversion_lw[col].apply(pd.to_numeric, errors = 'coerce')\n",
        "\n",
        "\n",
        "\n",
        "## competition and channel reach\n",
        "comp_chan_rch = comp_chan_rch.apply(pd.to_numeric, errors = 'ignore')\n",
        "\n",
        "\n",
        "## TV home promo\n",
        "tv_home_promo = tv_home_promo.apply(pd.to_numeric, errors = 'ignore')\n",
        "\n",
        "\n",
        "\n",
        "## TV nw promo\n",
        "\n",
        "tv_nw_promo = tv_nw_promo.replace(\"-\", np.nan)\n",
        "temp_nw= tv_nw_promo[\"regional_market_input_(pls_specify_markets_if_any)\"]\n",
        "reg_names_tv_nw = pd.Series(temp_nw).str.split(',').explode().str.strip().unique().tolist()\n",
        "\n",
        "reg_market_tv_nw = np.zeros((len(tv_nw_promo), len(reg_names_tv_nw)))\n",
        "for k, markets_str in enumerate(temp_nw):\n",
        "    if pd.notna(markets_str):\n",
        "        markets = [m.strip() for m in markets_str.split(',')]\n",
        "        indices = [reg_names_tv_nw.index(m) for m in markets if m in reg_names_tv_nw]\n",
        "        reg_market_tv_nw[k, indices] = 1\n",
        "\n",
        "reg_market_tv_nw_df = pd.DataFrame(reg_market_tv_nw, columns=[f'{name} (nw)' for name in reg_names_tv_nw])\n",
        "reg_market_tv_nw_df = reg_market_tv_nw_df.drop(columns= \"nan (nw)\")\n",
        "\n",
        "tv_nw_promo_without_rm = tv_nw_promo.drop(columns=[\"regional_market_input_(pls_specify_markets_if_any)\"], axis = 1)\n",
        "tv_nw_promo = pd.concat([tv_nw_promo_without_rm, reg_market_tv_nw_df], axis=1)\n",
        "tv_nw_promo = tv_nw_promo.apply(pd.to_numeric, errors = 'ignore')\n",
        "\n",
        "\n",
        "\n",
        "## tv osn promo\n",
        "tv_osn_promo = tv_osn_promo.replace(\"-\", np.nan)\n",
        "temp_osn = tv_osn_promo[\"regional_market_input_(pls_specify_markets_if_any)\"]\n",
        "regional_market_osn = pd.Series(temp_osn).str.split(',').explode().str.strip().unique().tolist()\n",
        "reg_mar_tv_osn = np.zeros((len(tv_osn_promo), len(regional_market_osn)))\n",
        "\n",
        "for k, markets_str in enumerate(temp_osn):\n",
        "    if pd.notna(markets_str):\n",
        "        markets = [m.strip() for m in markets_str.split(',')]\n",
        "        indices = [regional_market_osn.index(m) for m in markets if m in regional_market_osn]\n",
        "        reg_mar_tv_osn[k, indices] = 1\n",
        "\n",
        "reg_mar_tv_osn_df = pd.DataFrame(reg_mar_tv_osn, columns=[f'{name} (osn)' for name in regional_market_osn])\n",
        "reg_mar_tv_osn_df = reg_mar_tv_osn_df.drop(columns= \"nan (osn)\")\n",
        "\n",
        "tv_osn_promo_without_rm = tv_osn_promo.drop(columns=[\"regional_market_input_(pls_specify_markets_if_any)\"], axis = 1)\n",
        "tv_osn_promo = pd.concat([tv_osn_promo_without_rm, reg_mar_tv_osn_df], axis=1)\n",
        "tv_osn_promo = tv_osn_promo.apply(pd.to_numeric, errors = 'ignore')\n",
        "\n",
        "\n",
        "\n",
        "## digital\n",
        "\n",
        "temp_dg = digi_tg[\"markets\"]\n",
        "markets = pd.Series(temp_dg).str.split(',').explode().str.strip().unique().tolist()\n",
        "digi_mar = pd.get_dummies(temp_dg.str.split(',').explode().str.strip()).groupby(level=0).sum()\n",
        "\n",
        "digi_mar.columns = [col+\"(digi)\" for col in digi_mar.columns]\n",
        "digi_market_col = [col for col in digi_mar.columns if not any(char in col for char in '&\\n:')]\n",
        "digi_mar1 = digi_mar[digi_market_col]\n",
        "\n",
        "digi_tg = pd.concat([digi_tg.drop(columns=[\"markets\"]), digi_mar1], axis=1)\n",
        "digi_tg = digi_tg.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "UlWfFULPp53_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##social\n",
        "social_media_cc =  [col+\"(social video)\" for col in social_media.columns if col not in [\"shows\", \"social_video_spends_(yt,_fb,_insta,_sharechat,_etc)\"]]\n",
        "social_media.columns = [\"shows\", \"social_video_spends_(yt,_fb,_insta,_sharechat,_etc)\"] + social_media_cc\n",
        "social_media = social_media.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "g5ZuKcAA_Qj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ott\n",
        "ott_cc =  [col+\"(ott)\" for col in ott.columns if col not in [\"shows\", \"ott_spends_(hotstar,_zee5,_etc.)\"]]\n",
        "ott.columns = [\"shows\", \"ott_spends_(hotstar,_zee5,_etc.)\"] + ott_cc\n",
        "ott = ott.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "opAxlx6l_Qgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## gdn\n",
        "gdn_prog_cc =  [\"impressions(GDN)\", \"views(GDN)\", \"impact_spends_(ld_page_takeover)\"]\n",
        "gdn_prog.columns = [\"shows\", \"gdn/programmatic/xasis_spends\t\"] + gdn_prog_cc\n",
        "gdn_prog = gdn_prog.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "87-KxdWI_Qd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sub_mediums\n",
        "\n",
        "sub_mediums_cc = [\"impressions(sub_mediums)\", \"views(sub_mediums)\"]\n",
        "sub_mediums.columns = [\"shows\", \"sub_mediums\"] + sub_mediums_cc\n",
        "sub_mediums = sub_mediums.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "awpQ_gBF_QbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## others_glance_zapr\n",
        "\n",
        "others_glance_zapr_cc = [col+\"(oth_glance_zapr)\" for col in others_glance_zapr.columns if col not in [\"shows\", \"other_spends_(glance,_zapr,_ctv,_etc.)\"]]\n",
        "others_glance_zapr.columns = [\"shows\", \"other_spends_(glance,_zapr,_ctv,_etc.)\" ] + others_glance_zapr_cc\n",
        "others_glance_zapr = others_glance_zapr.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "ejn_A8Rr_QYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## overall_digi_spends\n",
        "overall_digi_spends = overall_digi_spends.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "CzWCod1K_QVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## influencers\n",
        "influencers = influencers.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "y_VK0QUE_QTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## dth_ooh_oga_cin_celeb\n",
        "dth_ooh_oga_cin_celeb = dth_ooh_oga_cin_celeb.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "E3UVFttq_QQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## social_own_earn\n",
        "social_own_earn = social_own_earn.apply(lambda col: pd.to_numeric(col, errors='coerce') if col.name != 'shows' else col)"
      ],
      "metadata": {
        "id": "sRAluz9k_QKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## pr_earned_new_metrics\n",
        "def extract_numeric(value):\n",
        "    numeric_part = pd.to_numeric(value.str.extract(r'([0-9]*\\.?[0-9]+)')[0], errors='coerce')\n",
        "    return numeric_part\n",
        "\n",
        "def replaced_genre(text):\n",
        "    if isinstance(text, str):\n",
        "        if \"-\" in text:\n",
        "            return text.split(\"-\", 1)[1].strip()\n",
        "        elif \"/\" in text:\n",
        "            return text.split(\"/\")[1].strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "pr_column = [\"total_pr_value_(from_prebuzz_to_launch)\", \"total_reach_(from_prebuzz_to_launch)\"]\n",
        "pr_earned_new_metrics[pr_column] = pr_earned_new_metrics[pr_column].apply(extract_numeric)\n",
        "pr_earned_new_metrics[\"replaced_genre\"] = pr_earned_new_metrics[\"which_show_&_genre_did_the_launch_show_replace\"].apply(replaced_genre)\n",
        "pr_earned_new_metrics = pr_earned_new_metrics.drop(columns=[\"which_show_&_genre_did_the_launch_show_replace\"])\n",
        "pr_earned_new_metrics = pr_earned_new_metrics.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "_fnG72T8_QHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## nw_grp_split\n",
        "\n",
        "nw_grp_split_cc = [col+\"(nw)\" for col in nw_grp_split.columns if col not in [\"shows\"]]\n",
        "nw_grp_split.columns = [\"shows\"] + nw_grp_split_cc\n",
        "nw_grp_split = nw_grp_split.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "lCPq4G7pWZWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## osn_grp_split\n",
        "osn_grp_split_cc = [col+\"(osn)\" for col in osn_grp_split.columns if col not in [\"shows\"]]\n",
        "osn_grp_split.columns = [\"shows\"] + osn_grp_split_cc\n",
        "osn_grp_split = osn_grp_split.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "1iQH4qZqWZRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## pre_slot_rch# Remove columns that are entirely NaN\n",
        "pre_slot_rch = pre_slot_rch.loc[:, pre_slot_rch.columns.notna()]\n",
        "pre_slot_rch = pre_slot_rch.apply(pd.to_numeric, errors = 'ignore')"
      ],
      "metadata": {
        "id": "OgYveEBlWIEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## combine the all dataframes to get D0\n",
        "show_dataframes = [show_details, launch_perf, conversion_ld, conversion_lw, comp_chan_rch, tv_home_promo, tv_nw_promo, tv_osn_promo, digi_tg, social_media, ott, gdn_prog, sub_mediums, others_glance_zapr, overall_digi_spends, influencers, dth_ooh_oga_cin_celeb, social_own_earn, pr_earned_new_metrics, nw_grp_split, osn_grp_split, pre_slot_rch]\n",
        "\n",
        "combine_df = show_dataframes[0]\n",
        "for df in show_dataframes[1:]:\n",
        "    combine_df = combine_df.merge(df, on='shows', how='left')"
      ],
      "metadata": {
        "id": "P6pZ3RyQFYPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_df.to_csv(\"D0_colors_data.csv\")"
      ],
      "metadata": {
        "id": "oAyGhTmhFYKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQllyZKB70hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3J97LW270ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzxwqowJ70bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6JyS0vF70Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skJhlRU370P7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}